{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0af865-93f4-44d7-ac3f-cf5cff1735b3",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58b3303-be0c-47fb-bcdb-e80b38eebafe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "This notebook demos a Retrieval Augmented Generation (RAG) feature on the scripts of Wet Toast Talk Radio.\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "* configure [AWS credentials](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html#cli-configure-files-examples)\n",
    "* setup `config.yaml`, e.g:\n",
    "\n",
    "```yaml\n",
    "media_store:\n",
    "  s3:\n",
    "    local: false\n",
    "    bucket_name: \"media-store-XXXXXXXXXXXX\" \n",
    "scriptwriter:\n",
    "  llm:\n",
    "    openai_api_key: sm:/wet-toast-talk-radio/scriptwriter/openai-api-key\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7244a99-b1a1-40e6-bf0e-82679257e884",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5e847b-7ae0-4902-b470-26255a478265",
   "metadata": {},
   "source": [
    "Setup AWS SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01684c4b-e0e4-4713-b044-db2186a18f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.Session()\n",
    "s3 = session.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f76d4a-cab3-412f-afac-df3495527345",
   "metadata": {},
   "source": [
    "Setup wet toast talk radio config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4335dbab-86a8-4c82-a755-8baa6fe3c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from wet_toast_talk_radio.command.root import load_config\n",
    "\n",
    "config_path = Path.cwd().parent / (\"config-s3.yml\")\n",
    "config = load_config(config_path)\n",
    "s3_config = config.media_store.s3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ed86e-cf51-437d-bdc7-f5d89f652a7b",
   "metadata": {},
   "source": [
    "We list all scripts from september and october, given that the last improvement to scriptwriter was done in late August."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba4b83e-7c7c-4196-934a-cdfdb116c0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-10-15 17:33:41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mListing objects               \u001b[0m \u001b[36mprefix\u001b[0m=\u001b[35mscript/2023-09\u001b[0m\n",
      "\u001b[2m2023-10-15 17:33:47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mListing objects               \u001b[0m \u001b[36mprefix\u001b[0m=\u001b[35mscript/2023-10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from wet_toast_talk_radio.disc_jockey.copy import Migrator\n",
    "\n",
    "september_prefix = \"script/2023-09\"\n",
    "october_prefix = \"script/2023-10\"\n",
    "\n",
    "migrator = Migrator(cfg=s3_config)\n",
    "september_objects = migrator.list_all_objects(september_prefix)\n",
    "october_objects = migrator.list_all_objects(october_prefix)\n",
    "objects = september_objects + october_objects\n",
    "scripts = [obj[\"Key\"] for obj in objects if obj[\"Key\"].endswith(\".jsonl\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda94e7-625a-41c7-a712-c5e3e76a9292",
   "metadata": {},
   "source": [
    "Download all scripts locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240fbe62-5c2f-44e7-96ee-8daec9e60e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd().parent / \"data\"\n",
    "data_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce1fdd5f-8dbe-4bd0-bd56-85c8c3da861a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-10-15 16:34:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDownloading scripts           \u001b[0m \u001b[36mcount\u001b[0m=\u001b[35m12595\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12595/12595 [17:48<00:00, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-10-15 16:52:47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDone downloading scripts\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from smart_open import open\n",
    "import structlog\n",
    "import concurrent\n",
    "from tqdm import tqdm\n",
    "\n",
    "logger = structlog.get_logger()\n",
    "\n",
    "def download_script(script: str):\n",
    "    (data_path / script).parent.mkdir(exist_ok=True, parents=True)\n",
    "    with open(f\"s3://{s3_config.bucket_name}/{script}\") as fin:\n",
    "        with open(data_path / script, \"w\") as fout:\n",
    "            fout.write(fin.read())\n",
    "\n",
    "logger.info(\"Downloading scripts\", count=len(scripts))\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=s3_config.max_workers) as executor:\n",
    "    futures = []\n",
    "    for script in scripts:\n",
    "        futures.append(executor.submit(download_script, script))\n",
    "    # Used to log progress\n",
    "    for _ in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "        pass\n",
    "\n",
    "logger.info(\"Done downloading scripts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1058c03-3763-4289-885d-dc7443cd7f39",
   "metadata": {},
   "source": [
    "Load each script in valid json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992ac216-1667-434d-a88e-48a8d7ee3957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12595/12595 [00:11<00:00, 1125.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from wet_toast_talk_radio.common.dialogue import Line, Speaker, read_lines\n",
    "from haystack import Document\n",
    "from tqdm import tqdm\n",
    "    \n",
    "def load_script(script_path: Path):\n",
    "    lines = read_lines(script_path)\n",
    "    lines = (f\"{l.speaker.name}: {l.content}\" for l in lines)\n",
    "    return {\"content\": \"\\n\".join(lines)}\n",
    "\n",
    "documents = []\n",
    "\n",
    "for script in tqdm(scripts):\n",
    "    script_json = load_script(data_path / script)\n",
    "    doc = Document.from_json(script_json)\n",
    "    documents.append(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a366c38-3e20-4926-a5f5-0df14ab7e236",
   "metadata": {},
   "source": [
    "## RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b8e2994-32a2-4669-9eda-64a93b650f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating BM25 representation...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12595/12595 [00:01<00:00, 6752.07 docs/s]\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore(use_bm25=True)\n",
    "document_store.write_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25284c36-e9c8-4265-a8b1-5085db2a21c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.nodes import BM25Retriever, PromptNode, PromptTemplate\n",
    "from haystack.nodes.prompt import PromptNode\n",
    "\n",
    "retriever = BM25Retriever(document_store, top_k=2)\n",
    "\n",
    "api_key = config.scriptwriter.llm.openai_api_key.value()\n",
    "qa_template = PromptTemplate(\"deepset/question-answering\")\n",
    "prompt_node = PromptNode(\"gpt-3.5-turbo\", api_key=api_key, default_prompt_template=qa_template)\n",
    "\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
    "rag_pipeline.add_node(component=prompt_node, name=\"prompt_node\", inputs=[\"retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f1c261cd-fb7f-45bf-9401-f866514c27ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Isabella'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print_answer = lambda out: pprint(out[\"results\"][0].strip())\n",
    "\n",
    "out = rag_pipeline.run(query=\"Who was debating with Wolfgang on the show The Great Debate?\")\n",
    "print_answer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50e30985-ee5f-4ecd-bee4-750eec3cf5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Wolfgang and Isabella were debating on the topic of driving under the '\n",
      " 'influence of drugs or alcohol.')\n"
     ]
    }
   ],
   "source": [
    "out = rag_pipeline.run(query=\"What were Wolfgang and Isabella debating on The Great Debate?\")\n",
    "print_answer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4333626c-357a-4cc5-97e2-1ee833a46ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Wolfgang's main arguments when debating Isabella on The Great Debate were \"\n",
      " 'that driving under the influence is dangerous, reckless, and puts innocent '\n",
      " 'lives at risk. He emphasized the need for responsible behavior and '\n",
      " 'prioritizing safety on the roads.')\n"
     ]
    }
   ],
   "source": [
    "out = rag_pipeline.run(query=\"What were Wolfgang's main arguments when debating Isabella on The Great Debate?\")\n",
    "print_answer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c952aae5-aa47-4d51-8d9f-0166d720a50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('It is not stated who won the debate between Wolfgang and Isabella on The '\n",
      " 'Great Debate.')\n"
     ]
    }
   ],
   "source": [
    "out = rag_pipeline.run(query=\"Who won the debate between Wolfgang and Isabella on The Great Debate?\")\n",
    "print_answer(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
